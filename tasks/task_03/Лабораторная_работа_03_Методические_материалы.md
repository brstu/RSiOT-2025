# ЛР03 — Kubernetes: состояние и хранение

План

- Обзор StatefulSet, Headless Service, PVC/PV, StorageClass, backup/restore.
- Практика: деплой stateful‑сервиса (Postgres/Redis/MinIO), проверка сохранности данных, резервное копирование и восстановление.
- Варианты (45) по параметрам хранилища и расписания backup.
- Материалы для чтения и раздел по отладке.

## Необходимые знания и ПО

- Кластер Kubernetes с поддержкой динамического провижининга (minikube с CSI или managed‑кластер), установлен `kubectl`.
- Базовое понимание работы баз данных (Postgres/Redis) или объектных хранилищ (MinIO).
- Знакомство с утилитами резервного копирования: `pg_dump`, `redis-cli`, `mc` (MinIO Client).

## Краткая теория

- StatefulSet — контроллер для stateful pod'ов, управляет идентичностью (имена с индексами), обеспечивает упорядоченный rollout/scale и стабильные сетевые идентификаторы.
- Headless Service (clusterIP: None) — создаёт стабильные DNS‑имена для каждого pod'а без балансировки нагрузки, необходим для прямого доступа к конкретным репликам.
- PVC/PV — абстракции для постоянного хранения данных; PersistentVolumeClaim запрашивает хранилище, PersistentVolume — физическое хранилище; StorageClass определяет тип и параметры динамического провижининга.
- Backup/Restore — критичны для stateful‑нагрузок: реализуются через Job/CronJob и специализированные утилиты (pg_dump/pg_restore для Postgres, redis-cli SAVE/BGSAVE для Redis, mc для MinIO).

## Практика

1. Выбор сервиса

   - Согласно варианту выберите Postgres, Redis или MinIO. Для Postgres — образ `postgres:16` или `bitnami/postgresql`; для Redis — `redis:7` или `bitnami/redis`; для MinIO — `minio/minio`.

2. Создайте Namespace и базовые манифесты

   - `namespace.yaml`

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: state01
```

- `secret.yaml`

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
  namespace: state01
type: Opaque
stringData:
  password: examplepass
```

- `statefulset.yaml`

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: db
  namespace: state01
spec:
  serviceName: db
  replicas: 1
  selector:
    matchLabels:
      app: db
  template:
    metadata:
      labels:
        app: db
    spec:
      containers:
        - name: db
          image: postgres:16
          ports:
            - containerPort: 5432
          env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: db-secret
                  key: password
          volumeMounts:
            - name: data
              mountPath: /var/lib/postgresql/data
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: standard
        resources:
          requests:
            storage: 2Gi
```

- `service.yaml` (Headless Service)

```yaml
apiVersion: v1
kind: Service
metadata:
  name: db
  namespace: state01
spec:
  clusterIP: None
  selector:
    app: db
  ports:
    - port: 5432
```

3. Деплой и проверка

- Примените манифесты и проверьте статус StatefulSet, Pod'ов и PVC.
- Создайте тестовые данные и убедитесь в их доступности.

4. Проверка сохранности данных

- Создайте таблицу/ключ в базе данных:
  - Postgres: `kubectl exec -it db-0 -n state01 -- psql -U postgres -c "CREATE TABLE test(id int); INSERT INTO test VALUES (1);"`
  - Redis: `kubectl exec -it db-0 -n state01 -- redis-cli SET mykey "value123"`
- Перезапустите pod: `kubectl delete pod db-0 -n state01`
- Дождитесь восстановления и проверьте наличие данных.

5. Backup/Restore

- Создайте CronJob для резервного копирования:
  - Postgres: используйте `pg_dump` для создания SQL-дампа
  - Redis: используйте `redis-cli SAVE` или `BGSAVE`
  - MinIO: используйте `mc mirror` для копирования объектов
- Сохраняйте архив в отдельный PVC или объектное хранилище.
- Создайте Job для восстановления данных из backup и продемонстрируйте успешное восстановление.

Пример CronJob для backup (Postgres):

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: db-backup
  namespace: state01
spec:
  schedule: "0 */6 * * *"  # каждые 6 часов
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: backup
              image: postgres:16
              command:
                - /bin/sh
                - -c
                - |
                  pg_dump -U postgres -h db-0.db.state01.svc.cluster.local postgres > /backup/backup-$(date +%Y%m%d-%H%M%S).sql
              env:
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: db-secret
                      key: password
              volumeMounts:
                - name: backup
                  mountPath: /backup
          volumes:
            - name: backup
              persistentVolumeClaim:
                claimName: backup-pvc
          restartPolicy: OnFailure
```

## Быстрый старт

Минимальные шаги для Postgres на `minikube`:

1. Запустите кластер: `minikube start`
1. При необходимости включите addons: `minikube addons enable volumesnapshots` и `minikube addons enable csi-hostpath-driver`
1. Убедитесь в наличии StorageClass: `kubectl get sc` (по умолчанию используйте `standard`)
1. Примените все манифесты: `kubectl apply -f ./k8s/`
1. Дождитесь готовности pod'а: `kubectl get pods -n state01 -w`
1. Создайте тестовые данные: `kubectl exec -it db-0 -n state01 -- psql -U postgres -c "CREATE TABLE test(id int); INSERT INTO test VALUES (1);"`
1. Перезапустите pod: `kubectl delete pod db-0 -n state01`; дождитесь восстановления
1. Проверьте сохранность данных: `kubectl exec -it db-0 -n state01 -- psql -U postgres -c "SELECT * FROM test;"`
1. Создайте PVC для backup: `kubectl apply -f backup-pvc.yaml`
1. Настройте CronJob для backup: `kubectl apply -f cronjob-backup.yaml`
1. Проверьте выполнение backup: `kubectl get jobs -n state01` и наличие файлов в PVC

## Критерии приёмки

- StatefulSet работает, PVC создан и смонтирован, данные переживают перезапуск pod'а (демонстрация с логами/скриншотами).
- Настроен и продемонстрирован механизм Backup через CronJob с корректным расписанием из варианта.
- Реализовано и показано восстановление данных из backup (Job для restore, логи успешного восстановления).
- Манифесты валидны, содержат метаданные (labels/annotations). Репозиторий содержит README с полным описанием архитектуры, шагов деплоя и проверок.

## Формат сдачи

- PR в основную ветку; назначить ревьювером `https://github.com/andreiNiasiuk`. В README: цели, архитектура хранения, параметры варианта, шаги деплоя и проверки, скриншоты/логи, демонстрация backup/restore.

См. варианты в файле `Варианты.md`.

## Материалы для чтения

- Kubernetes Docs: StatefulSets, Volumes, Persistent Volumes, StorageClass
  - https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
  - https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  - https://kubernetes.io/docs/concepts/storage/storage-classes/
- Примеры бэкапов: официальные инструкции Postgres/Redis, K8s CronJob
  - https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/
- Postgres Backup and Restore: https://www.postgresql.org/docs/current/backup.html
- Redis Persistence: https://redis.io/docs/management/persistence/

## Отладка и типичные ошибки

- PVC Pending: отсутствует подходящий StorageClass или CSI драйвер. Проверьте `kubectl get sc` и `kubectl describe pvc <pvc-name>`.
- Потеря данных: неверный mountPath или неиспользование volumeClaimTemplates (использован emptyDir вместо PVC).
- CronJob не запускается: проверьте расписание (формат crontab) и права на запись в PVC. Используйте `kubectl describe cronjob <name>` для диагностики.
- Pod не может запуститься: проверьте события через `kubectl describe pod <pod-name>` и логи через `kubectl logs <pod-name>`.
